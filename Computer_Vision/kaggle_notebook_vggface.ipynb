{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:13.829934Z",
     "iopub.status.busy": "2024-04-14T20:28:13.829481Z",
     "iopub.status.idle": "2024-04-14T20:28:28.906281Z",
     "shell.execute_reply": "2024-04-14T20:28:28.903851Z",
     "shell.execute_reply.started": "2024-04-14T20:28:13.829896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-image matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:28.910672Z",
     "iopub.status.busy": "2024-04-14T20:28:28.910213Z",
     "iopub.status.idle": "2024-04-14T20:28:43.938672Z",
     "shell.execute_reply": "2024-04-14T20:28:43.936942Z",
     "shell.execute_reply.started": "2024-04-14T20:28:28.910629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:43.94134Z",
     "iopub.status.busy": "2024-04-14T20:28:43.940732Z",
     "iopub.status.idle": "2024-04-14T20:28:43.952037Z",
     "shell.execute_reply": "2024-04-14T20:28:43.95062Z",
     "shell.execute_reply.started": "2024-04-14T20:28:43.94129Z"
    },
    "papermill": {
     "duration": 0.230891,
     "end_time": "2021-03-08T07:57:06.335029",
     "exception": false,
     "start_time": "2021-03-08T07:57:06.104138",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import io # Input/Output Module\n",
    "import os # OS interfaces\n",
    "import cv2 # OpenCV package\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from math import floor, ceil\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from urllib import request # module for opening HTTP requests\n",
    "from matplotlib import pyplot as plt # Plotting library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022868,
     "end_time": "2021-03-08T07:57:06.382109",
     "exception": false,
     "start_time": "2021-03-08T07:57:06.359241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Computer Vision\n",
    "---------------------------------------------------------------\n",
    "\n",
    "The goal of this notebook is to explore advanced techniques for constructing features that better describe objects of interest and to perform face recognition using these features.\n",
    "\n",
    "---------------------------------------------------------------\n",
    "This notebook is structured as follows:\n",
    "0. Data loading & Preprocessing\n",
    "1. Feature Representations\n",
    "2. Evaluation Metrics \n",
    "3. Classifiers\n",
    "4. Experiments\n",
    "5. Publishing best results\n",
    "6. Discussion\n",
    "\n",
    "---------------------------------------------------------------\n",
    "# 0. Data loading & Preprocessing\n",
    "\n",
    "## 0.1. Loading data\n",
    "The training set is many times smaller than the test set and this might strike you as odd, however, this is close to a real world scenario where the system might be put through daily use! In this notebook, I will try to do the best I can with the data that I've got! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a blacklist to remove the bad images from te training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:43.955613Z",
     "iopub.status.busy": "2024-04-14T20:28:43.955185Z",
     "iopub.status.idle": "2024-04-14T20:28:47.251134Z",
     "shell.execute_reply": "2024-04-14T20:28:47.249598Z",
     "shell.execute_reply.started": "2024-04-14T20:28:43.955579Z"
    },
    "papermill": {
     "duration": 37.543619,
     "end_time": "2021-03-08T07:57:43.9495",
     "exception": false,
     "start_time": "2021-03-08T07:57:06.405881",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "train = pd.read_csv(\n",
    "    '/kaggle/input/kul-h02a5a-computer-vision-ga1-2024/train_set.csv', index_col = 0)\n",
    "train.index = train.index.rename('id')\n",
    "\n",
    "test = pd.read_csv(\n",
    "    '/kaggle/input/kul-h02a5a-computer-vision-ga1-2024/test_set.csv', index_col = 0)\n",
    "test.index = test.index.rename('id')\n",
    "\n",
    "# read the images as numpy arrays and store in \"img\" column\n",
    "train['img'] = [cv2.cvtColor(np.load('/kaggle/input/kul-h02a5a-computer-vision-ga1-2024/train/train_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "                for index, row in train.iterrows()]\n",
    "\n",
    "test['img'] = [cv2.cvtColor(np.load('/kaggle/input/kul-h02a5a-computer-vision-ga1-2024/test/test_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "                for index, row in test.iterrows()]\n",
    "  \n",
    "\n",
    "train_size, test_size = len(train),len(test)\n",
    "\n",
    "\"The training set contains {} examples, the test set contains {} examples.\".format(train_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023377,
     "end_time": "2021-03-08T07:57:43.997466",
     "exception": false,
     "start_time": "2021-03-08T07:57:43.974089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Note: this dataset is a subset of the* [*VGG face dataset*](https://www.robots.ox.ac.uk/~vgg/data/vgg_face/).\n",
    "\n",
    "## 0.2. A first look\n",
    "Let's have a look at the data columns and class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:47.254908Z",
     "iopub.status.busy": "2024-04-14T20:28:47.253599Z",
     "iopub.status.idle": "2024-04-14T20:28:51.028971Z",
     "shell.execute_reply": "2024-04-14T20:28:51.0276Z",
     "shell.execute_reply.started": "2024-04-14T20:28:47.254858Z"
    },
    "papermill": {
     "duration": 3.315629,
     "end_time": "2021-03-08T07:57:47.336913",
     "exception": false,
     "start_time": "2021-03-08T07:57:44.021284",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The training set contains an identifier, name, image information and class label\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:51.031939Z",
     "iopub.status.busy": "2024-04-14T20:28:51.031514Z",
     "iopub.status.idle": "2024-04-14T20:28:54.770714Z",
     "shell.execute_reply": "2024-04-14T20:28:54.76954Z",
     "shell.execute_reply.started": "2024-04-14T20:28:51.031901Z"
    },
    "papermill": {
     "duration": 3.283501,
     "end_time": "2021-03-08T07:57:50.644778",
     "exception": false,
     "start_time": "2021-03-08T07:57:47.361277",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The test set only contains an identifier and corresponding image information.\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:54.773013Z",
     "iopub.status.busy": "2024-04-14T20:28:54.772416Z",
     "iopub.status.idle": "2024-04-14T20:28:54.787741Z",
     "shell.execute_reply": "2024-04-14T20:28:54.78646Z",
     "shell.execute_reply.started": "2024-04-14T20:28:54.77298Z"
    },
    "papermill": {
     "duration": 0.046628,
     "end_time": "2021-03-08T07:57:50.716317",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.669689",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The class distribution in the training set:\n",
    "train.groupby('name').agg({'img':'count', 'class': 'max'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025108,
     "end_time": "2021-03-08T07:57:50.766719",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.741611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that **Jesse is assigned the classification label 1**, and **Mila is assigned the classification label 2**. The dataset also contains 20 images of **look alikes (assigned classification label 0)** and the raw images. \n",
    "\n",
    "## 0.3. Preprocess data\n",
    "### 0.3.1 Example: HAAR face detector\n",
    "In the initial template of the notebook [HAAR feature based cascade classifiers](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html) was used to detect faces. The faces were resized so that they all have the same shape. If there are multiple faces in an image, it would only take the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:54.789889Z",
     "iopub.status.busy": "2024-04-14T20:28:54.789446Z",
     "iopub.status.idle": "2024-04-14T20:28:54.807976Z",
     "shell.execute_reply": "2024-04-14T20:28:54.806312Z",
     "shell.execute_reply.started": "2024-04-14T20:28:54.789856Z"
    },
    "papermill": {
     "duration": 0.042776,
     "end_time": "2021-03-08T07:57:50.834913",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.792137",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HAARPreprocessor():\n",
    "    \"\"\"Preprocessing pipeline built around HAAR feature based cascade classifiers. \"\"\"\n",
    "    \n",
    "    def __init__(self, path, face_size):\n",
    "        self.face_size = face_size\n",
    "        file_path = os.path.join(path, \"haarcascade_frontalface_default.xml\")\n",
    "        if not os.path.exists(file_path): \n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            self.download_model(file_path)\n",
    "        \n",
    "        self.classifier = cv2.CascadeClassifier(file_path)\n",
    "  \n",
    "    def download_model(self, path):\n",
    "        url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/\"\\\n",
    "            \"haarcascades/haarcascade_frontalface_default.xml\"\n",
    "        \n",
    "        with request.urlopen(url) as r, open(path, 'wb') as f:\n",
    "            f.write(r.read())\n",
    "            \n",
    "    def detect_faces(self, img):\n",
    "        \"\"\"Detect all faces in an image.\"\"\"\n",
    "        \n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        return self.classifier.detectMultiScale(\n",
    "            img_gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        \n",
    "    def extract_faces(self, img):\n",
    "        \"\"\"Returns all faces (cropped) in an image.\"\"\"\n",
    "        \n",
    "        faces = self.detect_faces(img)\n",
    "\n",
    "        return [img[y:y+h, x:x+w] for (x, y, w, h) in faces]\n",
    "    \n",
    "    def preprocess(self, data_row):\n",
    "        faces = self.extract_faces(data_row['img'])\n",
    "        \n",
    "        # if no faces were found, return None\n",
    "        if len(faces) == 0:\n",
    "            nan_img = np.empty(self.face_size + (3,))\n",
    "            nan_img[:] = np.nan\n",
    "            return nan_img\n",
    "        \n",
    "        # only return the first face\n",
    "        return cv2.resize(faces[0], self.face_size, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "    def __call__(self, data):\n",
    "        return np.stack([self.preprocess(row) for _, row in data.iterrows()]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3.1 Improvement: HAAR face detector\n",
    "\n",
    "While the code from HAARPreprocessor worked, it did not result into the wanted result for every trainings example. That's why the code is adjusted in the class HAARPreprocessorMultiple, which had better results in combination with futher proccesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:54.811355Z",
     "iopub.status.busy": "2024-04-14T20:28:54.810438Z",
     "iopub.status.idle": "2024-04-14T20:28:54.828072Z",
     "shell.execute_reply": "2024-04-14T20:28:54.826854Z",
     "shell.execute_reply.started": "2024-04-14T20:28:54.81132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HAARPreprocessorMultiple():\n",
    "    \"\"\"Preprocessing pipeline built around HAAR feature based cascade classifiers. \"\"\"\n",
    "    \n",
    "    def __init__(self, path, face_size):\n",
    "        self.face_size = face_size\n",
    "        file_path = os.path.join(path, \"haarcascade_frontalface_default.xml\")\n",
    "        if not os.path.exists(file_path): \n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            self.download_model(file_path)\n",
    "        \n",
    "        self.classifier = cv2.CascadeClassifier(file_path)\n",
    "  \n",
    "    def download_model(self, path):\n",
    "        url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/\"\\\n",
    "            \"haarcascades/haarcascade_frontalface_default.xml\"\n",
    "        \n",
    "        with request.urlopen(url) as r, open(path, 'wb') as f:\n",
    "            f.write(r.read())\n",
    "            \n",
    "    def detect_faces(self, img):\n",
    "        \"\"\"Detect all faces in an image.\"\"\"\n",
    "        \n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        return self.classifier.detectMultiScale(\n",
    "            img_gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        \n",
    "    def extract_faces(self, img):\n",
    "        \"\"\"Returns all faces (cropped) in an image.\"\"\"\n",
    "        \n",
    "        faces = self.detect_faces(img)\n",
    "\n",
    "        return [img[y:y+h, x:x+w] for (x, y, w, h) in faces]\n",
    "    \n",
    "    # preprocesses and returns first five faces\n",
    "    def preprocess(self, data_row):\n",
    "        faces = self.extract_faces(data_row['img'])\n",
    "        \n",
    "        # if no faces were found, return None\n",
    "        if len(faces) == 0:\n",
    "            nan_img = np.empty(self.face_size + (3,))\n",
    "            nan_img[:] = np.nan\n",
    "            return [nan_img]\n",
    "        \n",
    "        return [cv2.resize(face, self.face_size, interpolation = cv2.INTER_AREA) for face in faces]\n",
    "            \n",
    "    def __call__(self, data):\n",
    "        return [self.preprocess(row) for _, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3.1 (No Improvement): DNN Face Detector  \n",
    "\n",
    "Initially, the results of the HAAR detector for face extraction were deemed unsatisfactory, prompting an exploration of the DNN face detector as an alternative. However, this approach did not yield an improved score. Consequently, HAARPreprocessorMultiple was selected as the final preprocessor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:54.833475Z",
     "iopub.status.busy": "2024-04-14T20:28:54.833021Z",
     "iopub.status.idle": "2024-04-14T20:28:54.844394Z",
     "shell.execute_reply": "2024-04-14T20:28:54.843361Z",
     "shell.execute_reply.started": "2024-04-14T20:28:54.833426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# net = cv2.dnn.readNetFromCaffe(\"/kaggle/input/mod-face/deploy.prototxt\", \"/kaggle/input/mod-face/res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:54.847095Z",
     "iopub.status.busy": "2024-04-14T20:28:54.846716Z",
     "iopub.status.idle": "2024-04-14T20:28:54.868167Z",
     "shell.execute_reply": "2024-04-14T20:28:54.866872Z",
     "shell.execute_reply.started": "2024-04-14T20:28:54.847064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DNNPreprocessor():\n",
    "    \"\"\"Preprocessing pipeline built around DNN based face detection. \"\"\"\n",
    "\n",
    "    def __init__(self, net, face_size):\n",
    "        self.face_size = face_size\n",
    "        self.net = net\n",
    "\n",
    "    def detect_faces(self, img):\n",
    "        \"\"\"Detect all faces in an image.\"\"\"\n",
    "        # Get image dimensions\n",
    "        (h, w) = img.shape[:2]\n",
    "        # Preprocess the image\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        # Pass the blob through the network and perform inference\n",
    "        self.net.setInput(blob)\n",
    "        detections = self.net.forward()\n",
    "        # Initialize a list to store bounding box coordinates\n",
    "        bounding_boxes = []\n",
    "        # Loop over the detections\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            # Filter out weak detections\n",
    "            if confidence > 0.9:\n",
    "                # Compute the bounding box coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                # Add the bounding box coordinates to the list\n",
    "                bounding_boxes.append((startX, startY, endX, endY))\n",
    "        return bounding_boxes\n",
    "\n",
    "    def cut_out_faces(self, img, bounding_boxes):\n",
    "        \"\"\"Returns all faces (cropped) in an image.\"\"\"\n",
    "        # Initialize a list to store cropped faces\n",
    "        cropped_faces = []\n",
    "        # Loop through each bounding box\n",
    "        for (startX, startY, endX, endY) in bounding_boxes:\n",
    "            # Calculate the width and height of the bounding box\n",
    "            width = endX - startX\n",
    "            height = endY - startY\n",
    "\n",
    "            # Calculate the size of the margin (10% of the width/height)\n",
    "            margin = int(0.1 *  height)\n",
    "\n",
    "            # Calculate new start and end coordinates for the cropped face\n",
    "            new_startX = max(0, startX - margin)\n",
    "            new_startY = max(0, startY - margin)\n",
    "            new_endX = min(img.shape[1], endX + margin)\n",
    "            new_endY = min(img.shape[0], endY + margin)\n",
    "\n",
    "            # Ensure the cropped region is square\n",
    "            square_size = min(new_endY - new_startY, new_endX - new_startX)\n",
    "            new_endX = new_startX + square_size\n",
    "            new_endY = new_startY + square_size\n",
    "\n",
    "            # Crop the face from the image\n",
    "            face = img[new_startY:new_endY, new_startX:new_endX]\n",
    "            face = cv2.resize(face, (100, 100))\n",
    "            # Append the cropped face to the list\n",
    "            cropped_faces.append(face)\n",
    "\n",
    "        return cropped_faces\n",
    "\n",
    "    def preprocess(self, data_row):\n",
    "        faces = self.cut_out_faces(data_row['img'], self.detect_faces(data_row['img']))\n",
    "\n",
    "        # if no faces were found, return None\n",
    "        if len(faces) == 0:\n",
    "            nan_img = np.full(self.face_size + (3,), -1)  # Fill with -1 instead of np.nan\n",
    "            return nan_img\n",
    "\n",
    "        # only return the first face\n",
    "        return cv2.resize(faces[0], self.face_size, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return np.stack([self.preprocess(row) for _, row in data.iterrows()]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025332,
     "end_time": "2021-03-08T07:57:50.885849",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.860517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocces data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:54.870918Z",
     "iopub.status.busy": "2024-04-14T20:28:54.869826Z",
     "iopub.status.idle": "2024-04-14T20:28:58.004969Z",
     "shell.execute_reply": "2024-04-14T20:28:58.00368Z",
     "shell.execute_reply.started": "2024-04-14T20:28:54.870873Z"
    },
    "papermill": {
     "duration": 62.263517,
     "end_time": "2021-03-08T07:58:53.174859",
     "exception": false,
     "start_time": "2021-03-08T07:57:50.911342",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# parameter to play with \n",
    "FACE_SIZE = (100, 100)\n",
    "\n",
    "def plot_image_sequence(data, n, imgs_per_row=7):\n",
    "    n_rows = 1 + int(n/(imgs_per_row+1))\n",
    "    n_cols = min(imgs_per_row, n)\n",
    "\n",
    "    f,ax = plt.subplots(n_rows,n_cols, figsize=(10*n_cols,10*n_rows))\n",
    "    for i in range(n):\n",
    "        if n == 1:\n",
    "            ax.imshow(data[i])\n",
    "        elif n_rows > 1:\n",
    "            ax[int(i/imgs_per_row),int(i%imgs_per_row)].imshow(data[i])\n",
    "        else:\n",
    "            ax[int(i%n)].imshow(data[i])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# preprocessed data \n",
    "# preprocessor = DNNPreprocessor(net, face_size=FACE_SIZE)\n",
    "preprocessor = HAARPreprocessorMultiple(path = '../../tmp', face_size=FACE_SIZE)\n",
    "\n",
    "train_X_faces, train_y = preprocessor(train), train['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further proccesing**\n",
    "\n",
    "Analyzing the initial results of the preprocessor revealed instances where the wrong face was extracted from the training images or no face was detected at all. The following code blocks address these issues by manually removing incorrect extractions or selecting the correct face.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:28:58.007115Z",
     "iopub.status.busy": "2024-04-14T20:28:58.006741Z",
     "iopub.status.idle": "2024-04-14T20:29:58.440159Z",
     "shell.execute_reply": "2024-04-14T20:29:58.438782Z",
     "shell.execute_reply.started": "2024-04-14T20:28:58.007083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preprocessorMultiple = HAARPreprocessorMultiple(path = '../../tmp', face_size=FACE_SIZE)\n",
    "\n",
    "test_X_faces = preprocessorMultiple(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:29:58.442212Z",
     "iopub.status.busy": "2024-04-14T20:29:58.441834Z",
     "iopub.status.idle": "2024-04-14T20:29:58.452863Z",
     "shell.execute_reply": "2024-04-14T20:29:58.451444Z",
     "shell.execute_reply.started": "2024-04-14T20:29:58.442178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 14, 35, 39, 40\n",
    "train_X_faces[14] = [cv2.resize(train[\"img\"][14][80:240,70:230,:], (100, 100), interpolation = cv2.INTER_LINEAR)]\n",
    "train_X_faces[35] = [cv2.resize(train[\"img\"][35][50:130,190:260,:], (100, 100), interpolation = cv2.INTER_LINEAR)]\n",
    "train_X_faces[40] = [cv2.resize(train[\"img\"][40][80:260,100:220,:], (100, 100), interpolation = cv2.INTER_LINEAR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:29:58.455002Z",
     "iopub.status.busy": "2024-04-14T20:29:58.454579Z",
     "iopub.status.idle": "2024-04-14T20:29:58.466149Z",
     "shell.execute_reply": "2024-04-14T20:29:58.464997Z",
     "shell.execute_reply.started": "2024-04-14T20:29:58.454968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_X = []\n",
    "for i, row in enumerate(train_X_faces):\n",
    "    if i == 23:\n",
    "        train_X.append(row[1])\n",
    "    elif i == 24:\n",
    "        train_X.append(row[1])\n",
    "    elif i == 28:\n",
    "        train_X.append(row[2])\n",
    "    elif i == 49:\n",
    "        train_X.append(row[1])\n",
    "    elif i == 70:\n",
    "        train_X.append(row[2])\n",
    "    else:\n",
    "        train_X.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:29:58.46964Z",
     "iopub.status.busy": "2024-04-14T20:29:58.467596Z",
     "iopub.status.idle": "2024-04-14T20:29:58.497928Z",
     "shell.execute_reply": "2024-04-14T20:29:58.496342Z",
     "shell.execute_reply.started": "2024-04-14T20:29:58.469602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# remove images from the trainings data that don't contain information\n",
    "blacklist = [65]\n",
    "\n",
    "train_X = np.delete(train_X, blacklist, axis=0)\n",
    "train_y = np.delete(train_y, blacklist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:29:58.499899Z",
     "iopub.status.busy": "2024-04-14T20:29:58.499492Z",
     "iopub.status.idle": "2024-04-14T20:29:58.517111Z",
     "shell.execute_reply": "2024-04-14T20:29:58.515566Z",
     "shell.execute_reply.started": "2024-04-14T20:29:58.499866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_X = np.array(train_X).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise**\n",
    "\n",
    "Now that the data is cleaned, lets verify it by visually looking at the trainings examples for each class.\n",
    "Let's plot a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:29:58.51998Z",
     "iopub.status.busy": "2024-04-14T20:29:58.519582Z",
     "iopub.status.idle": "2024-04-14T20:30:02.957866Z",
     "shell.execute_reply": "2024-04-14T20:30:02.956469Z",
     "shell.execute_reply.started": "2024-04-14T20:29:58.519947Z"
    },
    "papermill": {
     "duration": 2.635787,
     "end_time": "2021-03-08T07:58:55.836611",
     "exception": false,
     "start_time": "2021-03-08T07:58:53.200824",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot faces of Michael and Sarah\n",
    "faces = train_X[train_y == 0]\n",
    "plot_image_sequence(faces, n=len(faces), imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:02.960303Z",
     "iopub.status.busy": "2024-04-14T20:30:02.959242Z",
     "iopub.status.idle": "2024-04-14T20:30:09.407334Z",
     "shell.execute_reply": "2024-04-14T20:30:09.405764Z",
     "shell.execute_reply.started": "2024-04-14T20:30:02.960259Z"
    },
    "papermill": {
     "duration": 3.840961,
     "end_time": "2021-03-08T07:58:59.72249",
     "exception": false,
     "start_time": "2021-03-08T07:58:55.881529",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot faces of Jesse\n",
    "faces = train_X[train_y == 1]\n",
    "plot_image_sequence(faces, n=len(faces), imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:09.409573Z",
     "iopub.status.busy": "2024-04-14T20:30:09.409144Z",
     "iopub.status.idle": "2024-04-14T20:30:15.857468Z",
     "shell.execute_reply": "2024-04-14T20:30:15.85653Z",
     "shell.execute_reply.started": "2024-04-14T20:30:09.409533Z"
    },
    "papermill": {
     "duration": 3.910256,
     "end_time": "2021-03-08T07:59:03.703299",
     "exception": false,
     "start_time": "2021-03-08T07:58:59.793043",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot faces of Mila\n",
    "faces = train_X[train_y == 2]\n",
    "plot_image_sequence(faces, n=len(faces), imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation**\n",
    "\n",
    "Random data augmentation is added to make the data more optimal for the models.\n",
    "Based on:\n",
    "* gaussian noise\n",
    "* random erasing\n",
    "* horizontal flip\n",
    "* adjusting the brightness\n",
    "\n",
    "It is determined randomly when these concepts are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.859785Z",
     "iopub.status.busy": "2024-04-14T20:30:15.859225Z",
     "iopub.status.idle": "2024-04-14T20:30:15.868766Z",
     "shell.execute_reply": "2024-04-14T20:30:15.867189Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.859743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image,p=0.5, mean=0, std=25):\n",
    "    if random.uniform(0, 1) > p:\n",
    "        return image\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    row, col, ch = image.shape\n",
    "    gauss = np.random.normal(mean, std, (row, col, ch))\n",
    "    noisy_image = np.clip(image + gauss, 0, 255)\n",
    "    noisy_image = noisy_image.astype(np.uint8)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.870907Z",
     "iopub.status.busy": "2024-04-14T20:30:15.870439Z",
     "iopub.status.idle": "2024-04-14T20:30:15.883361Z",
     "shell.execute_reply": "2024-04-14T20:30:15.881869Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.870856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def random_erasing(image, p=0.75, sl=0.02, sh=0.4, r1=0.3, r2=3):\n",
    "    if random.uniform(0, 1) > p:\n",
    "        return image\n",
    "\n",
    "    img_h, img_w, _ = image.shape\n",
    "    area = img_h * img_w\n",
    "\n",
    "    while True:\n",
    "        target_area = random.uniform(sl, sh) * area\n",
    "        aspect_ratio = random.uniform(r1, r2)\n",
    "        w = int(np.sqrt(target_area * aspect_ratio))\n",
    "        h = int(np.sqrt(target_area / aspect_ratio))\n",
    "        left = random.randint(0, img_w)\n",
    "        top = random.randint(0, img_h)\n",
    "\n",
    "        if left + w <= img_w and top + h <= img_h:\n",
    "            erased_image = np.copy(image)\n",
    "            erased_image[top:top + h, left:left + w, :] = np.random.rand(h, w, 3) * 255\n",
    "            return erased_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.885618Z",
     "iopub.status.busy": "2024-04-14T20:30:15.88518Z",
     "iopub.status.idle": "2024-04-14T20:30:15.8972Z",
     "shell.execute_reply": "2024-04-14T20:30:15.895793Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.885582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(image,p=0.25):\n",
    "    if random.uniform(0, 1) > p:\n",
    "        return image\n",
    "    return np.fliplr(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.899268Z",
     "iopub.status.busy": "2024-04-14T20:30:15.898809Z",
     "iopub.status.idle": "2024-04-14T20:30:15.909621Z",
     "shell.execute_reply": "2024-04-14T20:30:15.908124Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.899222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def adjust_brightness(image, probability=1, brightness_range=(0.7, 1.3), contrast_range=(0.7, 1.3)):\n",
    "    if random.uniform(0, 1) > probability:\n",
    "        return image\n",
    "    brightness_factor = random.uniform(*brightness_range)\n",
    "    contrast_factor = random.uniform(*contrast_range)\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=contrast_factor, beta=brightness_factor)\n",
    "\n",
    "    return adjusted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.912294Z",
     "iopub.status.busy": "2024-04-14T20:30:15.911543Z",
     "iopub.status.idle": "2024-04-14T20:30:15.919661Z",
     "shell.execute_reply": "2024-04-14T20:30:15.918339Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.912249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def random_augmentations(image,p=0.25):\n",
    "    image = add_gaussian_noise(image)\n",
    "    image = random_erasing(image)\n",
    "    image = horizontal_flip(image)\n",
    "    image = adjust_brightness(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100995,
     "end_time": "2021-03-08T07:59:03.904684",
     "exception": false,
     "start_time": "2021-03-08T07:59:03.803689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.4. Store Preprocessed data (optional)\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\". Feel free to use this to store intermediary results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.921379Z",
     "iopub.status.busy": "2024-04-14T20:30:15.920908Z",
     "iopub.status.idle": "2024-04-14T20:30:15.931688Z",
     "shell.execute_reply": "2024-04-14T20:30:15.930409Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.921335Z"
    },
    "papermill": {
     "duration": 0.109823,
     "end_time": "2021-03-08T07:59:04.11528",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.005457",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save preprocessed data\n",
    "# prep_path = '/kaggle/working/prepped_data/'\n",
    "# if not os.path.exists(prep_path):\n",
    "#     os.mkdir(prep_path)\n",
    "    \n",
    "# np.save(os.path.join(prep_path, 'train_X.npy'), train_X)\n",
    "# np.save(os.path.join(prep_path, 'train_y.npy'), train_y)\n",
    "# np.save(os.path.join(prep_path, 'test_X.npy'), test_X)\n",
    "\n",
    "# load preprocessed data\n",
    "# prep_path = '/kaggle/working/prepped_data/'\n",
    "# if not os.path.exists(prep_path):\n",
    "#     os.mkdir(prep_path)\n",
    "# train_X = np.load(os.path.join(prep_path, 'train_X.npy'))\n",
    "# train_y = np.load(os.path.join(prep_path, 'train_y.npy'))\n",
    "# test_X = np.load(os.path.join(prep_path, 'test_X.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100212,
     "end_time": "2021-03-08T07:59:04.516059",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.415847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Feature Representations\n",
    "## 1.0. Example: Identify feature extractor\n",
    "The example feature extractor doesn't actually do anything... It just returns the input:\n",
    "$$\n",
    "\\forall x : f(x) = x.\n",
    "$$\n",
    "\n",
    "It does make for a good placeholder and baseclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.933805Z",
     "iopub.status.busy": "2024-04-14T20:30:15.933404Z",
     "iopub.status.idle": "2024-04-14T20:30:15.94623Z",
     "shell.execute_reply": "2024-04-14T20:30:15.944862Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.933772Z"
    },
    "papermill": {
     "duration": 0.108781,
     "end_time": "2021-03-08T07:59:04.725071",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.61629",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class IdentityFeatureExtractor:\n",
    "    \"\"\"A simple function that returns the input\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.134288,
     "end_time": "2021-03-08T07:59:04.959911",
     "exception": false,
     "start_time": "2021-03-08T07:59:04.825623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1. Baseline 1: HOG feature extractor/Scale Invariant Feature Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG Feature Extractor\n",
    "\n",
    "The Histogram of Oriented Gradients (HOG) is a feature descriptor that analyzes the distribution of gradient orientations within localized regions of an image. This method primarily captures the structural and shape-related characteristics of objects.\n",
    "\n",
    "The process begins by dividing the image into small, non-overlapping cells. The selection of cell size is a key design choice; in this case, 8x8 pixel cells were used, with the image resized to 64x64 pixels.\n",
    "\n",
    "Next, the image gradient is computed, derived from both the magnitude and angle of intensity changes at each pixel. These gradients are then grouped into 8x8 cells to form blocks. Within each block, a 9-bin histogram is generated, where each bin represents a 20-degree range of gradient angles.\n",
    "\n",
    "The cells are further organized into larger blocks of equal size, with 2x2 blocks utilized in this implementation.\n",
    "\n",
    "Finally, block-wise normalization is applied to minimize the impact of contrast variations across images of the same object, improving the robustness of the extracted features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.958542Z",
     "iopub.status.busy": "2024-04-14T20:30:15.957852Z",
     "iopub.status.idle": "2024-04-14T20:30:15.969965Z",
     "shell.execute_reply": "2024-04-14T20:30:15.968875Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.958481Z"
    },
    "papermill": {
     "duration": 0.110122,
     "end_time": "2021-03-08T07:59:05.171171",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.061049",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "class HOGFeatureExtractor(IdentityFeatureExtractor):\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.params = params\n",
    "        self.histograms = []\n",
    "        self.visual_representation = []\n",
    "        self.tsne_transformed_data = None\n",
    "        \n",
    "        \n",
    "    def transform(self, X):        \n",
    "        for instance in X:\n",
    "            instance = np.array(instance, dtype='uint8')\n",
    "            instance_rsz = cv2.resize(instance, (64, 64))\n",
    "            instance_rsz_gray = cv2.cvtColor(instance_rsz, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            hist, hog_image = hog(instance_rsz_gray, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize=True)\n",
    "            \n",
    "            self.histograms.append(hist)\n",
    "            self.visual_representation.append(hog_image)\n",
    "\n",
    "        return self.histograms\n",
    "    \n",
    "    def tsne_transform(self, n_components=2):\n",
    "        tsne = TSNE(n_components=n_components, learning_rate='auto', init='pca', random_state = 26)\n",
    "        self.tsne_transformed_data = tsne.fit_transform(np.array(self.histograms))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hog function from skimage is used to compute the features. This function comes with a added result which can be used to visualize the results.\n",
    "\n",
    "The following transformations are applied on the data:\n",
    "* Resize the image to 64x64\n",
    "* Convert the image to grayscale\n",
    "* Apply the HOG algorithm with the parameters specified above, the output of this functions are the features computed by HOG and a visualization of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:15.972478Z",
     "iopub.status.busy": "2024-04-14T20:30:15.971743Z",
     "iopub.status.idle": "2024-04-14T20:30:18.226613Z",
     "shell.execute_reply": "2024-04-14T20:30:18.225442Z",
     "shell.execute_reply.started": "2024-04-14T20:30:15.972433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hog_feature_extractor = HOGFeatureExtractor()\n",
    "hists = hog_feature_extractor.transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:18.22938Z",
     "iopub.status.busy": "2024-04-14T20:30:18.228613Z",
     "iopub.status.idle": "2024-04-14T20:30:30.812999Z",
     "shell.execute_reply": "2024-04-14T20:30:30.811809Z",
     "shell.execute_reply.started": "2024-04-14T20:30:18.229335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_image_sequence(hog_feature_extractor.visual_representation, n=50, imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100377,
     "end_time": "2021-03-08T07:59:05.372401",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.272024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1.1. t-SNE Plots\n",
    "t-SNE stands for t-Distributed Stochastic Neighbor Embedding. It is a machine learning algorithm for visualization. It is a nonlinear dimensionality reduction technique well-suited for embedding high-dimensional data for visualization in a low-dimensional space of two or three dimensions.\n",
    "\n",
    "Similar objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability.\n",
    "\n",
    "The t-SNE plot is a scatter plot that visualizes the clusters or groups of similar data points based on their similarity in the high-dimensional space. Each point in the plot corresponds to a specific sample in the dataset.\n",
    "\n",
    "It can be used to understand the underlying structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:30.815165Z",
     "iopub.status.busy": "2024-04-14T20:30:30.814791Z",
     "iopub.status.idle": "2024-04-14T20:30:31.393423Z",
     "shell.execute_reply": "2024-04-14T20:30:31.392449Z",
     "shell.execute_reply.started": "2024-04-14T20:30:30.815133Z"
    },
    "papermill": {
     "duration": 0.100308,
     "end_time": "2021-03-08T07:59:05.57403",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.473722",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hog_feature_extractor.tsne_transform()\n",
    "tsne_result = hog_feature_extractor.tsne_transformed_data\n",
    "tsne_result_data = {'tsne_x': tsne_result[:,0], 'tsne_y': tsne_result[:,1], 'face': train_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:31.396121Z",
     "iopub.status.busy": "2024-04-14T20:30:31.395291Z",
     "iopub.status.idle": "2024-04-14T20:30:31.792617Z",
     "shell.execute_reply": "2024-04-14T20:30:31.791325Z",
     "shell.execute_reply.started": "2024-04-14T20:30:31.396079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "sns.scatterplot(x ='tsne_x', y='tsne_y', data=tsne_result_data, s=100, hue='face')\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(['Michael and Sarah', 'Jesse', 'Mila'], loc=3, title='Faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100596,
     "end_time": "2021-03-08T07:59:05.775686",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.67509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1.2. Discussion\n",
    "\n",
    "The cluster representing Mila is distinctly separated from the rest of the data. However, there is noticeable overlap between the clusters of Jesse and Michael & Sarah. This is expected, as Jesse and Michael share similar facial features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT Feature extractor**\n",
    "\n",
    "SIFT stands for Scale-Invariant Feature Transform and it is a technique in computer vision used to detect and describe local features in images. It’s robust to changes in rotation, scale, and illumination. The process involves identifying key locations, assigning an orientation, and creating a descriptor based on local image gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are the steps:\n",
    "1. Normalizing the image\n",
    "2. Applying the SIFT detector\n",
    "3. Returning the descriptors with corresponding keypoints\n",
    "\n",
    "The descriptors can be used to train a model. However not all images have the same amount of descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:31.794877Z",
     "iopub.status.busy": "2024-04-14T20:30:31.794386Z",
     "iopub.status.idle": "2024-04-14T20:30:31.807268Z",
     "shell.execute_reply": "2024-04-14T20:30:31.806024Z",
     "shell.execute_reply.started": "2024-04-14T20:30:31.794835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SIFTFeatureExtractor(IdentityFeatureExtractor):\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.params = params\n",
    "        self.visual_representation = []\n",
    "        self.tsne_transformed_data = None\n",
    "        self.keypoints = []\n",
    "        self.descriptors = []\n",
    "        \n",
    "    def transform(self, X):\n",
    "        for instance in X:          \n",
    "            instance = np.array(instance, dtype='uint8')\n",
    "            instance_rsz = cv2.resize(instance, (64, 64)) \n",
    "             # Converting image to grayscale\n",
    "            instance_rsz_gray = cv2.cvtColor(instance_rsz,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "            # Applying SIFT detector\n",
    "            sift = cv2.SIFT_create()\n",
    "            # kp = sift.detect(instance_rsz_gray, None)\n",
    "            kp, des = sift.detectAndCompute(instance_rsz_gray, None)\n",
    "            \n",
    "            if des is None:\n",
    "                des = np.empty((0, 128))\n",
    " \n",
    "            # Marking the keypoint on the image using circles\n",
    "            sift_image_kp = cv2.drawKeypoints(instance_rsz_gray ,\n",
    "                                  kp ,\n",
    "                                  instance_rsz ,\n",
    "                                  flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        \n",
    "            self.visual_representation.append(sift_image_kp)\n",
    "            self.keypoints.append(kp)\n",
    "            self.descriptors.append(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:31.809255Z",
     "iopub.status.busy": "2024-04-14T20:30:31.808853Z",
     "iopub.status.idle": "2024-04-14T20:30:32.098876Z",
     "shell.execute_reply": "2024-04-14T20:30:32.096761Z",
     "shell.execute_reply.started": "2024-04-14T20:30:31.809222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sift_feature_extractor = SIFTFeatureExtractor()\n",
    "sift_feature_extractor.transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vizualisation shows the detected keypoints by the SIFT detector on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:32.100755Z",
     "iopub.status.busy": "2024-04-14T20:30:32.100379Z",
     "iopub.status.idle": "2024-04-14T20:30:43.744977Z",
     "shell.execute_reply": "2024-04-14T20:30:43.743846Z",
     "shell.execute_reply.started": "2024-04-14T20:30:32.100723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_image_sequence(sift_feature_extractor.visual_representation, n=50, imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Discussion\n",
    "\n",
    "While SIFT is effective in feature detection, it proved challenging to apply in a classification context. The main issue encountered was the lack of consistency in the number of features returned by SIFT, making it extremely difficult to train a machine learning model. As a result, it was decided not to use SIFT further in the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.101426,
     "end_time": "2021-03-08T07:59:05.978236",
     "exception": false,
     "start_time": "2021-03-08T07:59:05.87681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Baseline 2: PCA feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce Dimension**\n",
    "\n",
    "To begin with PCA, the image dataset is first converted into a 2D matrix. The images are initially transformed into grayscale, which reduces some of the dimensionality. This reduction in dimensionality helps make computations more efficient. Afterward, the images are flattened, creating the `trainingFaces` variable, which holds a list of flattened face vectors. Finally, mean-subtraction is performed to center the data around the origin, helping to reduce bias and improve the effectiveness of subsequent computations.\n",
    "\n",
    "**SVD**\n",
    "\n",
    "Once the data is preprocessed, the computation of eigenfaces begins. Singular Value Decomposition (SVD) is applied to the flattened faces. While SVD yields several results, the primary focus is on the U matrix (the left singular values), which contains the eigenfaces. While Eigenvalue Decomposition (EVD) could be an alternative, SVD is preferred due to its greater robustness, particularly in scenarios with noisy data or missing values.\n",
    "\n",
    "The number of non-zero eigenvalues or singular values retained depends on the specific dataset and the desired level of information retention. A general rule of thumb is to keep enough components to explain a significant portion of the data's variance.\n",
    "\n",
    "**Plot**\n",
    "\n",
    "The plotted data displays the average of all training faces on the left and the first eigenface on the right. The first eigenface is derived from the U matrix obtained through SVD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:43.747352Z",
     "iopub.status.busy": "2024-04-14T20:30:43.746909Z",
     "iopub.status.idle": "2024-04-14T20:30:44.053674Z",
     "shell.execute_reply": "2024-04-14T20:30:44.052559Z",
     "shell.execute_reply.started": "2024-04-14T20:30:43.747314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nfaces = len(train_X)\n",
    "m = FACE_SIZE[0]\n",
    "n = FACE_SIZE[1]\n",
    "\n",
    "gray_faces = np.array([cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY) for image in train_X])\n",
    "trainingFaces = np.swapaxes(np.array([(np.swapaxes(x,0,1)).flatten() for x in gray_faces]),0,1)\n",
    "avgFace = np.mean(trainingFaces,axis=1) # size n*m by 1\n",
    "\n",
    "# Compute eigenfaces on mean-subtracted training data\n",
    "X = trainingFaces - np.tile(avgFace,(trainingFaces.shape[1],1)).T\n",
    "U, S, VT = np.linalg.svd(X,full_matrices=0)\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(121)\n",
    "img_avg = ax1.imshow(np.reshape(avgFace,(m,n)).T)\n",
    "img_avg.set_cmap('gray')\n",
    "plt.axis('off')\n",
    "\n",
    "ax2 = fig1.add_subplot(122)\n",
    "img_u1 = ax2.imshow(np.reshape(U[:,0],(m,n)).T)\n",
    "img_u1.set_cmap('gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class incorporates code to transform faces into their principal components and vice versa. Upon instantiation of this class, the number of components can be specified. Subsequently, the eigenfaces are computed based on the training data previously generated.\n",
    "\n",
    "The `transform` method converts a list of faces into a list of their corresponding principal components.\n",
    "\n",
    "Conversely, the `inverse_transform` method reverses this process, converting a list of principal components back into a reconstruction of the original faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:44.056449Z",
     "iopub.status.busy": "2024-04-14T20:30:44.055655Z",
     "iopub.status.idle": "2024-04-14T20:30:44.069298Z",
     "shell.execute_reply": "2024-04-14T20:30:44.06803Z",
     "shell.execute_reply.started": "2024-04-14T20:30:44.056408Z"
    },
    "papermill": {
     "duration": 0.111032,
     "end_time": "2021-03-08T07:59:06.191215",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.080183",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PCAFeatureExtractor(IdentityFeatureExtractor):\n",
    "\n",
    "    # converts face images to gray values and reshapes the data so that each column represents data of a face\n",
    "    def __prepare_data__(self, X):\n",
    "      grayX = np.array([cv2.cvtColor(x.astype(np.uint8), cv2.COLOR_RGB2GRAY) for x in X])\n",
    "      flattenX = np.swapaxes(np.array([x.flatten() for x in grayX]),0,1)\n",
    "\n",
    "      return flattenX\n",
    "\n",
    "\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "\n",
    "        X = self.__prepare_data__(train_X)\n",
    "        self.avgX = np.mean(X,axis=1)\n",
    "\n",
    "        X = X - np.tile(self.avgX, (X.shape[1],1)).T\n",
    "        U, S, VT = np.linalg.svd(X,full_matrices=0)\n",
    "\n",
    "        self.U = U.copy()\n",
    "\n",
    "    def transform(self, Y):\n",
    "      X = self.__prepare_data__(Y)\n",
    "      X = X - np.tile(self.avgX, (X.shape[1],1)).T\n",
    "\n",
    "      return np.swapaxes(self.U[:,:self.n_components].T @ X, 0, 1)\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "      return self.avgX + np.swapaxes(self.U[:,:self.n_components]  @ np.swapaxes(X, 0, 1),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100881,
     "end_time": "2021-03-08T07:59:06.392861",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.29198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.1. Eigenface Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates varying results when reconstructing a face using different numbers of components that PCA can utilize for reconstruction.\n",
    "\n",
    "Through analysis of these results, it becomes evident that increasing the number of components leads to better reconstructions, which aligns with logical expectations. Beyond 50 components, PCA achieves a reconstruction closely resembling the original face. Consequently, it can be concluded that 50 components should suffice for classification purposes, as selecting a higher number may risk overfitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:44.072007Z",
     "iopub.status.busy": "2024-04-14T20:30:44.070916Z",
     "iopub.status.idle": "2024-04-14T20:30:46.779814Z",
     "shell.execute_reply": "2024-04-14T20:30:46.778396Z",
     "shell.execute_reply.started": "2024-04-14T20:30:44.071957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# face reconstruction\n",
    "testFace = train_X[60]\n",
    "gray_face = cv2.cvtColor(testFace.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(cv2.cvtColor(testFace.astype(np.uint8), cv2.COLOR_RGB2GRAY))\n",
    "plt.set_cmap('gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "r_list = [5, 10, 15, 20, 30, 40, 50, 60, 70, 79]\n",
    "mse_values = []\n",
    "for r in r_list:\n",
    "  feature_extractor = PCAFeatureExtractor(r)\n",
    "  pca_features = feature_extractor.transform([testFace])\n",
    "  reconFace = feature_extractor.inverse_transform(pca_features)\n",
    "  mse = mean_squared_error(gray_face, np.reshape(reconFace,(m,n)))\n",
    "  mse_values.append(mse)\n",
    "\n",
    "  img = plt.imshow(np.reshape(reconFace,(m,n)))\n",
    "  img.set_cmap('gray')\n",
    "  plt.title('r = ' + str(r))\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot depicts the decrease in mean squared error (MSE) between the reconstructed face and the original face with an increasing number of components. Notably, the MSE consistently decreases as more components are used. By employing 50 components, a significant drop in MSE is observed. This trend underscores the effectiveness of using PCA for reconstruction tasks, where a higher number of components results in increasingly accurate reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:46.781812Z",
     "iopub.status.busy": "2024-04-14T20:30:46.78143Z",
     "iopub.status.idle": "2024-04-14T20:30:47.116899Z",
     "shell.execute_reply": "2024-04-14T20:30:47.114148Z",
     "shell.execute_reply.started": "2024-04-14T20:30:46.781781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(r_list, mse_values, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('MSE vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code constructs all eigenfaces for PCA with a total of 50 components, resulting in 50 eigenfaces. These eigenfaces are then plotted to provide a clearer understanding of their appearance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:47.118974Z",
     "iopub.status.busy": "2024-04-14T20:30:47.118518Z",
     "iopub.status.idle": "2024-04-14T20:30:47.18687Z",
     "shell.execute_reply": "2024-04-14T20:30:47.184888Z",
     "shell.execute_reply.started": "2024-04-14T20:30:47.118933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_components = 50\n",
    "\n",
    "nfaces = len(train_X)\n",
    "m = FACE_SIZE[0]\n",
    "n = FACE_SIZE[1]\n",
    "\n",
    "gray_faces = np.array([cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY) for image in train_X])\n",
    "trainingFaces = np.swapaxes(np.array([x.flatten() for x in gray_faces]),0,1)\n",
    "avgFace = np.mean(trainingFaces,axis=1) # size n*m by 1\n",
    "\n",
    "# Compute eigenfaces on mean-subtracted training data\n",
    "X = trainingFaces - np.tile(avgFace,(trainingFaces.shape[1],1)).T\n",
    "U, S, VT = np.linalg.svd(X,full_matrices=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:47.190221Z",
     "iopub.status.busy": "2024-04-14T20:30:47.189268Z",
     "iopub.status.idle": "2024-04-14T20:30:59.002134Z",
     "shell.execute_reply": "2024-04-14T20:30:59.000341Z",
     "shell.execute_reply.started": "2024-04-14T20:30:47.190161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_image_sequence([np.reshape(x, FACE_SIZE) for x in np.swapaxes(U[:,:n_components],0,1)], n=n_components, imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the face-features plot visualization, the faces are positioned based on the eigenface values they represent. This plot allows for a visual assessment of which faces have comparable representations for the first two eigenfaces when transformed by PCA. By observing the spacing between PCA features, interpretation becomes more intuitive and straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:59.00428Z",
     "iopub.status.busy": "2024-04-14T20:30:59.003875Z",
     "iopub.status.idle": "2024-04-14T20:30:59.875162Z",
     "shell.execute_reply": "2024-04-14T20:30:59.873931Z",
     "shell.execute_reply.started": "2024-04-14T20:30:59.004248Z"
    },
    "papermill": {
     "duration": 0.100638,
     "end_time": "2021-03-08T07:59:06.595002",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.494364",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "gray_faces = np.array([cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY) for image in train_X])\n",
    "trainingFaces = np.swapaxes(np.array([x.flatten() for x in gray_faces]),0,1)\n",
    "avgY = np.mean(trainingFaces,axis=1) # size n*m by 1\n",
    "Y = trainingFaces - np.tile(avgY,(trainingFaces.shape[1],1)).T\n",
    "\n",
    "features = np.swapaxes(U[:,:2].T @ Y, 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(features[:,0], features[:,1])\n",
    "\n",
    "for i, y in enumerate(gray_faces):\n",
    "    ab = AnnotationBbox(OffsetImage(np.reshape(y.astype(np.uint8), (100, 100)), zoom=0.1, cmap='gray'),\n",
    "                        (features[i, 0], features[i, 1]), frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "plt.xlabel(\"Eigenface 1\")\n",
    "plt.ylabel(\"Eigenface 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.101263,
     "end_time": "2021-03-08T07:59:06.797448",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.696185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.2. Feature Space Plots\n",
    "The next plot illustrates how the first two features are distributed when transformed with PCA. In this visualization, the features of person 1 are depicted in red, while those of person 2 are represented in black. By examining this visualization, it becomes apparent that the data points are almost linearly separable, suggesting that a simple linear boundary between the data points of each label could effectively classify each face. This observation holds promise for subsequent face classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:30:59.876823Z",
     "iopub.status.busy": "2024-04-14T20:30:59.876478Z",
     "iopub.status.idle": "2024-04-14T20:31:00.260086Z",
     "shell.execute_reply": "2024-04-14T20:31:00.258821Z",
     "shell.execute_reply.started": "2024-04-14T20:30:59.876795Z"
    },
    "papermill": {
     "duration": 0.101801,
     "end_time": "2021-03-08T07:59:07.000598",
     "exception": false,
     "start_time": "2021-03-08T07:59:06.898797",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PCA_features = PCAFeatureExtractor(10).transform(train_X)\n",
    "\n",
    "f1 = 0\n",
    "f2 = 1\n",
    "\n",
    "p1 = 1\n",
    "p2 = 2\n",
    "\n",
    "plt.plot(PCA_features[train_y == p1][:,f1], PCA_features[train_y == p1][:,f2],'d',color='k',label='Person 0')\n",
    "plt.plot(PCA_features[train_y == p2][:,f1], PCA_features[train_y == p2][:,f2],'^',color='r',label='Person 1')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following PCA plot, the data is visualized in three dimensions, with each axis representing a different feature from PCA. The plot clearly shows distinct clusters of data points with the same labels, which suggests a strong foundation for future face classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:00.261985Z",
     "iopub.status.busy": "2024-04-14T20:31:00.261629Z",
     "iopub.status.idle": "2024-04-14T20:31:00.707098Z",
     "shell.execute_reply": "2024-04-14T20:31:00.705821Z",
     "shell.execute_reply.started": "2024-04-14T20:31:00.261955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PCA_features = PCAFeatureExtractor(10).transform(train_X)\n",
    "\n",
    "f1 = 0\n",
    "f2 = 1\n",
    "f3 = 2\n",
    "\n",
    "p1 = 1\n",
    "p2 = 2\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "for p in range(3):\n",
    "  ax.scatter(PCA_features[train_y == p][:,f1], PCA_features[train_y == p][:,f2], PCA_features[train_y == p][:,f3], color=['r','g','b'][p], label=f\"Person {p}\");\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.102099,
     "end_time": "2021-03-08T07:59:07.204783",
     "exception": false,
     "start_time": "2021-03-08T07:59:07.102684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.3. Discussion\n",
    "\n",
    "Principal Component Analysis (PCA) applied to facial image datasets provides crucial insights and prepares the data for subsequent tasks like classification. Through visualizations and analyses, the process of dimensionality reduction, eigenface computation, and the potential benefits of PCA in classification were examined.\n",
    "\n",
    "PCA proves to be a valuable tool for reducing dimensionality and extracting features from facial image datasets. By transforming the data while retaining key information, PCA establishes a solid foundation for future classification tasks, enabling more efficient and accurate facial image analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.10088,
     "end_time": "2021-03-08T07:59:07.406787",
     "exception": false,
     "start_time": "2021-03-08T07:59:07.305907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Evaluation Metrics\n",
    "## 2.0. Example: Accuracy\n",
    "As example metric I take the accuracy. Informally, accuracy is the proportion of correct predictions over the total amount of predictions. It is used a lot in classification but it certainly has its disadvantages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:00.708966Z",
     "iopub.status.busy": "2024-04-14T20:31:00.708611Z",
     "iopub.status.idle": "2024-04-14T20:31:00.714198Z",
     "shell.execute_reply": "2024-04-14T20:31:00.712995Z",
     "shell.execute_reply.started": "2024-04-14T20:31:00.708936Z"
    },
    "papermill": {
     "duration": 1.180116,
     "end_time": "2021-03-08T07:59:08.688561",
     "exception": false,
     "start_time": "2021-03-08T07:59:07.508445",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification_report function is also imported from sklearn because accuracy does not tells us a lot about how robust the model is. With this function we can look at the precision, recall  and f1-score of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:00.715809Z",
     "iopub.status.busy": "2024-04-14T20:31:00.715425Z",
     "iopub.status.idle": "2024-04-14T20:31:00.724351Z",
     "shell.execute_reply": "2024-04-14T20:31:00.72345Z",
     "shell.execute_reply.started": "2024-04-14T20:31:00.715777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.103749,
     "end_time": "2021-03-08T07:59:08.894358",
     "exception": false,
     "start_time": "2021-03-08T07:59:08.790609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Classifiers\n",
    "## 3.0. Example: The *'not so smart'* classifier\n",
    "This random classifier is not very complicated. It makes predictions at random, based on the distribution obseved in the training set. **It thus assumes** that the class labels of the test set will be distributed similarly to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:00.726187Z",
     "iopub.status.busy": "2024-04-14T20:31:00.725681Z",
     "iopub.status.idle": "2024-04-14T20:31:00.734492Z",
     "shell.execute_reply": "2024-04-14T20:31:00.733674Z",
     "shell.execute_reply.started": "2024-04-14T20:31:00.726157Z"
    },
    "papermill": {
     "duration": 0.113194,
     "end_time": "2021-03-08T07:59:09.110222",
     "exception": false,
     "start_time": "2021-03-08T07:59:08.997028",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomClassificationModel:\n",
    "    \"\"\"Random classifier, draws a random sample based on class distribution observed \n",
    "    during training.\"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Adjusts the class ratio instance variable to the one observed in y. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : tensor\n",
    "            Training set\n",
    "        y : array\n",
    "            Training set labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : RandomClassificationModel\n",
    "        \"\"\"\n",
    "        \n",
    "        self.classes, self.class_ratio = np.unique(y, return_counts=True)\n",
    "        self.class_ratio = self.class_ratio / self.class_ratio.sum()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Samples labels for the input data. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : tensor\n",
    "            dataset\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_star : array\n",
    "            'Predicted' labels\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(0)\n",
    "        return np.random.choice(self.classes, size = X.shape[0], p=self.class_ratio)\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first classifiers explored was Nearest Neighbours. This is a very classic, well-known classifier. However, the performance of both the HOG and PCA feature extractors wasn't that good. A combination of the HOG and the PCA features was additionally also explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:00.736309Z",
     "iopub.status.busy": "2024-04-14T20:31:00.735829Z",
     "iopub.status.idle": "2024-04-14T20:31:03.121668Z",
     "shell.execute_reply": "2024-04-14T20:31:03.120604Z",
     "shell.execute_reply.started": "2024-04-14T20:31:00.73628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "feature_extractor_PCA = PCAFeatureExtractor(100)\n",
    "pca_result = feature_extractor_PCA.transform(train_X)\n",
    "feature_extractor_HOG = HOGFeatureExtractor()\n",
    "HOG_result = feature_extractor_HOG.transform(train_X)\n",
    "\n",
    "# HOG has big dimension so I don't know how much this helps\n",
    "features = np.hstack((pca_result, HOG_result))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(features, train_y)\n",
    "\n",
    "print(f'Cross validation:\\n {cross_val_score(neigh, features, train_y, cv=10)}')\n",
    "\n",
    "'''\n",
    "feature_extractor_PCA = PCAFeatureExtractor(100)\n",
    "pca_result = feature_extractor_PCA.transform(test_X)\n",
    "feature_extractor_HOG = HOGFeatureExtractor()\n",
    "HOG_result = feature_extractor_HOG.transform(test_X)\n",
    "\n",
    "features_test = np.hstack((pca_result, HOG_result))\n",
    "\n",
    "test_y_star = neigh.predict(features_test)\n",
    "\n",
    "# evaluate performance of the model on the training set\n",
    "train_y_star = neigh.predict(features)\n",
    "\n",
    "\"The performance on the Test set is {:.2f}. This however, does not tell us much about the actual performance (generalisability).\".format(\n",
    "    accuracy_score(train_y, train_y_star))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.128206Z",
     "iopub.status.busy": "2024-04-14T20:31:03.125763Z",
     "iopub.status.idle": "2024-04-14T20:31:03.137738Z",
     "shell.execute_reply": "2024-04-14T20:31:03.13652Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.128161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LRClassificationModel:\n",
    "    def __init__(self):\n",
    "        self.lr_model = LogisticRegression(C=1.0, \n",
    "                                           verbose=0, \n",
    "                                           class_weight='balanced', \n",
    "                                           dual=False,\n",
    "                                           fit_intercept=False, \n",
    "                                           intercept_scaling=3, \n",
    "                                           max_iter=200, \n",
    "                                           multi_class='auto', \n",
    "                                           n_jobs=None, penalty='l2', \n",
    "                                           random_state=None, \n",
    "                                           solver='lbfgs', \n",
    "                                           tol=0.01)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #X_train = self.get_feature_extractor.transform(X)\n",
    "        self.lr_model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        #X_test = self.get_feature_extractor.transform(X)\n",
    "        return self.lr_model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        #X_test = self.feature_extractor_instance.transform(X)\n",
    "        return self.lr_model.predict_proba(X)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.lr_model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper parameters**\n",
    "\n",
    "In the next block of code grid search is done to find the optimal hyper parameters for the model. This only had to be done once and that is why it is been commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.140694Z",
     "iopub.status.busy": "2024-04-14T20:31:03.139561Z",
     "iopub.status.idle": "2024-04-14T20:31:03.157472Z",
     "shell.execute_reply": "2024-04-14T20:31:03.156201Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.14065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# random grid search to find the best hyper parameters for Logistic Regression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "'''\n",
    "#feature_extractor = PCAFeatureExtractor(100)\n",
    "#pca_features = feature_extractor.transform(train_X)\n",
    "hog_feature_extractor = HOGFeatureExtractor()\n",
    "hog_features = hog_feature_extractor.transform(train_X)\n",
    "\n",
    "# Use a random grid search to find the best hyper parameters\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.1, 1.0, 2.0, 5.0, 10.0],  # Regularization parameter\n",
    "    'tol': [0.1, 0.01, 0.001, 0.0001],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga', 'newton-cg', 'sag'],  # Solver options\n",
    "    'max_iter': [50, 100, 200, 500, 1000, 2000],  # Maximum number of iterations\n",
    "    'penalty' : ['l2'],\n",
    "    'verbose' : [0, 1, 2]\n",
    "    }\n",
    "# Initialize logistic regression model\n",
    "lr_model = LogisticRegression(class_weight='balanced', multi_class='auto', fit_intercept=False)\n",
    "# Perform grid search\n",
    "# Perform randomized grid search\n",
    "random_search = RandomizedSearchCV(lr_model, param_distributions=param_dist, n_iter=500,\n",
    "                                   scoring='accuracy', cv=5, verbose=0, random_state=42)\n",
    "random_search.fit(pca_features, train_y)\n",
    "# Get best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best hyperparameters: {best_params}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Support Vector Machine\n",
    "Both SVC and lineairSVC have been explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.159878Z",
     "iopub.status.busy": "2024-04-14T20:31:03.159212Z",
     "iopub.status.idle": "2024-04-14T20:31:03.171776Z",
     "shell.execute_reply": "2024-04-14T20:31:03.170773Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.159845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class SVCClassificationModel:\n",
    "    def __init__(self):\n",
    "        self.svm_model = SVC(C=2.086, \n",
    "                             class_weight=None, \n",
    "                             coef0=3.929, \n",
    "                             decision_function_shape='ovo', \n",
    "                             degree=3, gamma='scale', \n",
    "                             kernel='rbf', \n",
    "                             max_iter=10000, \n",
    "                             shrinking=False, \n",
    "                             tol=0.0970105895663254)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.svm_model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.svm_model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.svm_model.predict_proba(X)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.174083Z",
     "iopub.status.busy": "2024-04-14T20:31:03.173111Z",
     "iopub.status.idle": "2024-04-14T20:31:03.187921Z",
     "shell.execute_reply": "2024-04-14T20:31:03.186598Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.174051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class LineairSVCClassificationModel:\n",
    "    def __init__(self):\n",
    "        self.svm_model =  LinearSVC(C=3.65,\n",
    "                                    class_weight='balanced', \n",
    "                                    fit_intercept=True, \n",
    "                                    intercept_scaling=9.65, \n",
    "                                    max_iter=150, tol=0.096)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.svm_model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.svm_model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.svm_model.predict_proba(X)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.svm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper parameters**\n",
    "\n",
    "In the next block of code did grid search is done to find the optimal hyper parameters for the model. This only had to be done once and that is why it is been commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.190358Z",
     "iopub.status.busy": "2024-04-14T20:31:03.189688Z",
     "iopub.status.idle": "2024-04-14T20:31:03.20187Z",
     "shell.execute_reply": "2024-04-14T20:31:03.200811Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.190324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# random parameter search for SMV \n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "'''\n",
    "#augmented_train_X\n",
    "#augmented_train_y \n",
    "#feature_extractor = PCAFeatureExtractor(100)\n",
    "#pca_features_train = feature_extractor.transform(reduced_train_X)\n",
    "#hog_feature_extractor = HOGFeatureExtractor()\n",
    "#hog_features_train = hog_feature_extractor.transform(augmented_train_X)\n",
    "feature_extractor = PCAFeatureExtractor(100)\n",
    "pca_features_train = feature_extractor.transform(augmented_train_X)\n",
    "\n",
    "\n",
    "\n",
    "svm_model = LinearSVC()\n",
    "param_distributions = {\"C\": uniform(1, 10), \n",
    "                       \"tol\": uniform(0.0001, 0.1),\n",
    "                       \"max_iter\": [100, 500, 1000, 2000],\n",
    "                       \"fit_intercept\": [True, False],\n",
    "                       \"intercept_scaling\": uniform(0.1, 10),\n",
    "                       \"class_weight\": [None, \"balanced\"]}\n",
    "\n",
    "random_search = RandomizedSearchCV(svm_model, param_distributions, n_iter=200, cv=5, verbose=2)\n",
    "random_search.fit(hog_features_train, augmented_train_y)\n",
    "\n",
    "print(f\"Best hyperparameters: {random_search.best_params_}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Convolutional neural network\n",
    "Tested with the convolutional neural network but did not see any good results from it so did not look further into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.204247Z",
     "iopub.status.busy": "2024-04-14T20:31:03.203601Z",
     "iopub.status.idle": "2024-04-14T20:31:03.218891Z",
     "shell.execute_reply": "2024-04-14T20:31:03.217721Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.204213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "\n",
    "augmented_train_X, augmented_train_y = generate_augmented_data(train_X, train_y)\n",
    "\n",
    "# building the input vector from the augmented data\n",
    "X_train = augmented_train_X.reshape(augmented_train_X.shape[0], 100, 100, 3)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 3\n",
    "print(\"Shape before one-hot encoding: \", augmented_train_y.shape)\n",
    "Y_train = to_categorical(augmented_train_y, n_classes)\n",
    "#print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
    "\n",
    "conv_model = Sequential()\n",
    "conv_model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(100,100,3)))\n",
    "conv_model.add(MaxPool2D(pool_size=(2,2)))\n",
    "conv_model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "conv_model.add(MaxPool2D(pool_size=(2,2)))\n",
    "conv_model.add(Dropout(0.25))\n",
    "conv_model.add(Flatten())\n",
    "conv_model.add(Dense(128, activation='relu'))\n",
    "conv_model.add(Dropout(0.5))\n",
    "conv_model.add(Dense(n_classes, activation='softmax'))  # Change to match the number of classes\n",
    "\n",
    "# compiling the sequential model\n",
    "conv_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "conv_model.fit(X_train, Y_train, batch_size=32, epochs=30)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 XGBoost\n",
    "Lastly, XGBoost was also explored, but did not see any good results from it so did not look further into it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.221024Z",
     "iopub.status.busy": "2024-04-14T20:31:03.220469Z",
     "iopub.status.idle": "2024-04-14T20:31:03.235446Z",
     "shell.execute_reply": "2024-04-14T20:31:03.234444Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.22099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Convert data into DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(pca_features, label=train_y)\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # multiclass classification\n",
    "    'num_class': 3,                 # number of classes\n",
    "    'eval_metric': 'merror'         # evaluation metric\n",
    "}\n",
    "# Train the XGBoost model\n",
    "num_rounds = 100\n",
    "#xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.102942,
     "end_time": "2021-03-08T07:59:09.730342",
     "exception": false,
     "start_time": "2021-03-08T07:59:09.6274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Experiments\n",
    "\n",
    "\n",
    "## 4.0. Example: basic pipeline\n",
    "The basic pipeline takes any input and samples a label based on the class label distribution of the training set. As expected the performance is very poor, predicting approximately 1/4 correctly on the training set. There is a lot of room for improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation** \n",
    "\n",
    "To maximize the amount of training data available to our classifiers, augmented data is added to the training set. This augmented data is added in order to help generalize the classifier better by including more varied training data. This is a well-known technique used when training data is sparse. When used, observed a slight improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.237732Z",
     "iopub.status.busy": "2024-04-14T20:31:03.236949Z",
     "iopub.status.idle": "2024-04-14T20:31:03.250832Z",
     "shell.execute_reply": "2024-04-14T20:31:03.249611Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.237684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# adds an augmented version of each remaining image\n",
    "import numpy as np\n",
    "\n",
    "# updated \n",
    "def generate_augmented_data(train_X, train_y):\n",
    "    augmented_train_X = []\n",
    "    augmented_train_y = []\n",
    "\n",
    "    for i in range(len(train_X)):\n",
    "        augmented_train_X.append(train_X[i])\n",
    "        augmented_train_y.append(train_y[i])\n",
    "        \n",
    "        for _ in range(20):\n",
    "            aug = random_augmentations(train_X[i], p=1)\n",
    "            augmented_train_X.append(aug)\n",
    "            augmented_train_y.append(train_y[i])\n",
    "\n",
    "    # Convert the lists to ndarrays before returning\n",
    "    augmented_train_X = np.stack(augmented_train_X)\n",
    "    augmented_train_y = np.array(augmented_train_y)\n",
    "\n",
    "    return augmented_train_X, augmented_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:03.253002Z",
     "iopub.status.busy": "2024-04-14T20:31:03.252288Z",
     "iopub.status.idle": "2024-04-14T20:31:07.148456Z",
     "shell.execute_reply": "2024-04-14T20:31:07.147301Z",
     "shell.execute_reply.started": "2024-04-14T20:31:03.252966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "augmented_train_X = np.zeros((0, train_X.shape[1], train_X.shape[2], train_X.shape[3])).astype(np.uint8)\n",
    "augmented_train_y = np.zeros((0)).astype(np.uint8)\n",
    "samples = 40\n",
    "for index, X in enumerate(train_X):\n",
    "    augmented_train_X = np.concatenate((augmented_train_X, [random_augmentations(X) for i in range(samples)]), axis=0)\n",
    "    augmented_train_y = np.concatenate((augmented_train_y, [train_y[index] for i in range(samples)]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:31:07.150167Z",
     "iopub.status.busy": "2024-04-14T20:31:07.149852Z",
     "iopub.status.idle": "2024-04-14T20:31:08.512777Z",
     "shell.execute_reply": "2024-04-14T20:31:08.511541Z",
     "shell.execute_reply.started": "2024-04-14T20:31:07.150139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_X_augmented, train_y_augmented = generate_augmented_data(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Review of Classifiers\n",
    "\n",
    "Various classifiers were evaluated in combination with different feature extraction methods, using a small validation set for demonstration purposes. Due to the limited size of the validation set, the results obtained may not fully reflect the model's performance in a real-world scenario. During testing, it was observed that Logistic Regression (LR) with Histogram of Oriented Gradients (HOG) performed the best as a standalone model for classifying faces. However, combining Support Vector Machine (SVM) with Principal Component Analysis (PCA) and LR with HOG resulted in a higher score than LR with HOG alone. It is important to note that in a real-world context, a different combination of classifier and feature extractor may yield better results than those observed on the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to review classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def best_features_for_model(model, train_X, train_y, test_X, test_y):\n",
    "    # different trainingsdata representations\n",
    "        #PCA 80\n",
    "    feature_extractor_PCA = PCAFeatureExtractor(80)\n",
    "    pca_result_80 = feature_extractor_PCA.transform(train_X)\n",
    "    pca_result_80_test = feature_extractor_PCA.transform(test_X)\n",
    "\n",
    "    \n",
    "        #PCA 50\n",
    "    feature_extractor_PCA = PCAFeatureExtractor(50)\n",
    "    pca_result_50 = feature_extractor_PCA.transform(train_X)\n",
    "    pca_result_50_test = feature_extractor_PCA.transform(test_X)\n",
    "\n",
    "    \n",
    "        # HOG transfrom\n",
    "    feature_extractor_HOG = HOGFeatureExtractor()\n",
    "    HOG_result = feature_extractor_HOG.transform(train_X)\n",
    "    feature_extractor_HOG = HOGFeatureExtractor()\n",
    "    HOG_result_test = feature_extractor_HOG.transform(test_X)\n",
    "\n",
    "        # Combinations\n",
    "    combined = np.hstack((pca_result_80, HOG_result))\n",
    "    combined_test = np.hstack((pca_result_80_test, HOG_result_test))\n",
    "    \n",
    "    \n",
    "        # Augmented data PCA\n",
    "    train_X_augmented, train_y_augmented = generate_augmented_data(train_X, train_y)\n",
    "    feature_extractor_PCA = PCAFeatureExtractor(80)\n",
    "    pca_result_80_aug = feature_extractor_PCA.transform(train_X_augmented)\n",
    "  \n",
    "    \n",
    "        # Augmented data HOG\n",
    "    feature_extractor_HOG = HOGFeatureExtractor()\n",
    "    HOG_result_aug = feature_extractor_HOG.transform(train_X_augmented)\n",
    "    \n",
    "        # Combinations augmented\n",
    "    combined_aug = np.hstack((pca_result_80_aug, HOG_result_aug))    \n",
    "    \n",
    "    train_sets = [{'Name trainset' : 'PCA 80', 'train_X' : pca_result_80, 'train_y' : train_y,'test_X' : pca_result_80_test, 'test_y' : test_y},\n",
    "                 {'Name trainset' : 'PCA 50', 'train_X' : pca_result_50, 'train_y' : train_y,'test_X' : pca_result_50_test, 'test_y' : test_y},\n",
    "                 {'Name trainset' : 'Hog', 'train_X' : HOG_result, 'train_y' : train_y,'test_X' : HOG_result_test, 'test_y' : test_y},\n",
    "                 {'Name trainset' : 'Combined', 'train_X' : combined, 'train_y' : train_y, 'test_X' : combined_test, 'test_y' : test_y},\n",
    "                 {'Name trainset' : 'Augmented PCA', 'train_X' : pca_result_80_aug, 'train_y' : train_y_augmented, 'test_X' : pca_result_80_test, 'test_y' : test_y},\n",
    "                 {'Name trainset' : 'Augmented HOG', 'train_X' : HOG_result_aug, 'train_y' : train_y_augmented, 'test_X' : HOG_result_test, 'test_y' : test_y},\n",
    "                 {'Name trainset' : 'Augmented Combined', 'train_X' : combined_aug, 'train_y' : train_y_augmented, 'test_X' : combined_test, 'test_y' : test_y}\n",
    "\n",
    "                 ]\n",
    "    scores =[]\n",
    "    \n",
    "    for train_set in train_sets:\n",
    "        print(train_set['Name trainset'])\n",
    "        model.fit(train_set['train_X'], train_set['train_y'])\n",
    "        train_acc = accuracy_score(model.predict(train_set['test_X']), train_set['test_y'])\n",
    "        scores.append({ 'train_set' : train_set['Name trainset'], 'test_acc' : train_acc})\n",
    "        print(classification_report(model.predict(train_set['test_X']), train_set['test_y'], labels=[0, 1, 2]))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "The results indicate that the HOG feature extraction method provides the best performance when used with Logistic Regression. Both the original and augmented HOG methods achieved high accuracy (0.95 and 0.90 respectively), precision, recall, and F1-score across all classes.\n",
    "\n",
    "In contrast, the PCA and Combined methods, both original and augmented, showed lower performance metrics.\n",
    "\n",
    "Therefore, for this particular task and dataset, Logistic Regression paired with HOG appears to be the most effective approach.\n",
    "\n",
    "Keep in mind that the validation set is very small. So the results on the test set may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:48:40.360871Z",
     "iopub.status.busy": "2024-04-14T20:48:40.360457Z",
     "iopub.status.idle": "2024-04-14T20:49:20.431355Z",
     "shell.execute_reply": "2024-04-14T20:49:20.429774Z",
     "shell.execute_reply.started": "2024-04-14T20:48:40.36084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_size = 20\n",
    "\n",
    "combined = list(zip(train_X, train_y))\n",
    "random.shuffle(combined)\n",
    "X, y = zip(*combined)\n",
    "\n",
    "validation_X = X[-validation_size:]\n",
    "validation_y = y[-validation_size:]\n",
    "\n",
    "X = X[:-validation_size]\n",
    "y = y[:-validation_size]\n",
    "\n",
    "lr_model = LRClassificationModel()\n",
    "best_features_for_model(lr_model, X, y, validation_X, validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Classifier**\n",
    "\n",
    "The SVC performs best with the HOG feature extraction method, both in its original and augmented forms, achieving an accuracy of 0.90 and 0.95 respectively.\n",
    "\n",
    "The Combined methods, original and augmented, showed lower performance metrics. But SVC also works well with PCA.\n",
    "\n",
    "Thus, for this particular task and dataset, SVC paired with HOG appears to be the most effective approach. \n",
    "\n",
    "Keep in mind that the validation set is very small. So the results on the test set may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:49:23.255073Z",
     "iopub.status.busy": "2024-04-14T20:49:23.254662Z",
     "iopub.status.idle": "2024-04-14T20:50:01.605797Z",
     "shell.execute_reply": "2024-04-14T20:50:01.604527Z",
     "shell.execute_reply.started": "2024-04-14T20:49:23.255042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_size = 20\n",
    "\n",
    "combined = list(zip(train_X, train_y))\n",
    "random.shuffle(combined)\n",
    "X, y = zip(*combined)\n",
    "\n",
    "validation_X = X[-validation_size:]\n",
    "validation_y = y[-validation_size:]\n",
    "\n",
    "X = X[:-validation_size]\n",
    "y = y[:-validation_size]\n",
    "\n",
    "lr_model = SVCClassificationModel()\n",
    "best_features_for_model(lr_model, X, y, validation_X, validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-nearest neighbor**\n",
    "\n",
    "The KNN classifier shows the best performance with the HOG feature extraction method, achieving an accuracy of 0.80.\n",
    "\n",
    "The PCA and Combined methods, both original and augmented, showed similar performance metrics with an accuracy of 0.80 and 0.70 respectively.\n",
    "\n",
    "However, the performance of KNN with the Augmented HOG method dropped slightly to an accuracy of 0.70.\n",
    "\n",
    "In conclusion, for this particular task and dataset, KNN paired with HOG appears to be the most effective approach.\n",
    "\n",
    "Keep in mind that the validation set is very small. So the results on the test set may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:50:01.608951Z",
     "iopub.status.busy": "2024-04-14T20:50:01.608176Z",
     "iopub.status.idle": "2024-04-14T20:50:38.827759Z",
     "shell.execute_reply": "2024-04-14T20:50:38.826683Z",
     "shell.execute_reply.started": "2024-04-14T20:50:01.608918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_size = 20\n",
    "\n",
    "combined = list(zip(train_X, train_y))\n",
    "random.shuffle(combined)\n",
    "X, y = zip(*combined)\n",
    "\n",
    "validation_X = X[-validation_size:]\n",
    "validation_y = y[-validation_size:]\n",
    "\n",
    "X = X[:-validation_size]\n",
    "y = y[:-validation_size]\n",
    "\n",
    "lr_model = KNeighborsClassifier(n_neighbors=5)\n",
    "best_features_for_model(lr_model, X, y, validation_X, validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:33:06.986908Z",
     "iopub.status.busy": "2024-04-14T20:33:06.986283Z",
     "iopub.status.idle": "2024-04-14T20:33:06.995956Z",
     "shell.execute_reply": "2024-04-14T20:33:06.9943Z",
     "shell.execute_reply.started": "2024-04-14T20:33:06.986857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_X_indices = []\n",
    "for i, faces in enumerate(test_X_faces):\n",
    "    for _ in faces:\n",
    "        test_X_indices.append(i)\n",
    "test_X_indices = np.array(test_X_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:33:06.998279Z",
     "iopub.status.busy": "2024-04-14T20:33:06.997798Z",
     "iopub.status.idle": "2024-04-14T20:33:07.370067Z",
     "shell.execute_reply": "2024-04-14T20:33:07.369011Z",
     "shell.execute_reply.started": "2024-04-14T20:33:06.998236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_X = []\n",
    "for faces in test_X_faces:\n",
    "    for face in faces:\n",
    "        test_X.append(face)\n",
    "test_X = np.array(test_X).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block a Support Vector Classifier (SVC) is trained using features extracted from images through Principal Component Analysis (PCA). The augmented training data is utilized to fit this model. Once trained, the model is employed to make predictions on the test set. These predictions include confidence scores for each label, indicating the model's level of certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:33:07.381222Z",
     "iopub.status.busy": "2024-04-14T20:33:07.380453Z",
     "iopub.status.idle": "2024-04-14T20:33:08.664569Z",
     "shell.execute_reply": "2024-04-14T20:33:08.66331Z",
     "shell.execute_reply.started": "2024-04-14T20:33:07.381163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PCA (SVC)\n",
    "pca_feature_extractor = PCAFeatureExtractor(50)\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "pca_features_train = pca_feature_extractor.transform(train_X_augmented)\n",
    "svc.fit(pca_features_train, train_y_augmented)\n",
    "\n",
    "# do cross validation, commented out to reduce output \n",
    "#print(f'Cross validation:\\n {cross_val_score(svc, pca_features_train, train_y_augmented, cv=10)}')\n",
    "\n",
    "pca_features_test = pca_feature_extractor.transform(test_X)\n",
    "test_y_prob_pca = svc.predict_proba(pca_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block a Logistic Regression Classifier (LRC) is trained using features extracted from images through Principal Component Analysis (PCA). The augmented training data is alse utilized to fit this model. Once trained, the model is employed to make predictions on the test set. These predictions include confidence scores for each label, such as the output obtained by the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:33:08.666511Z",
     "iopub.status.busy": "2024-04-14T20:33:08.666109Z",
     "iopub.status.idle": "2024-04-14T20:34:58.636385Z",
     "shell.execute_reply": "2024-04-14T20:34:58.634654Z",
     "shell.execute_reply.started": "2024-04-14T20:33:08.666467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# HOG (LR)\n",
    "lrc = LRClassificationModel()\n",
    "\n",
    "hog_feature_extractor = HOGFeatureExtractor()\n",
    "hog_features_train = hog_feature_extractor.transform(train_X_augmented)\n",
    "lrc.fit(hog_features_train, train_y_augmented)\n",
    "# do cross validation, commented out to reduce output \n",
    "#print(f'Cross validation:\\n {cross_val_score(lrc.get_model(), hog_features_train, train_y_augmented, cv=10)}')\n",
    "\n",
    "hog_feature_extractor = HOGFeatureExtractor() # Have to make new isntance \n",
    "hog_features_test = hog_feature_extractor.transform(test_X)\n",
    "test_y_prob_hog = lrc.predict_proba(hog_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `classify_rules` accepts a list of predictions generated by multiple models. Each model makes predictions for all faces extracted from the image and assigns a confidence/probability to these predictions. By aggregating this data, the `classify_rules` method selects the prediction with the highest confidence from all models. If other models also exhibit high confidence in the chosen prediction, it is returned. Otherwise, the method defaults to predicting class 0.\n",
    "\n",
    "This `classify_rules` method is then applied to each face in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:34:58.639861Z",
     "iopub.status.busy": "2024-04-14T20:34:58.638794Z",
     "iopub.status.idle": "2024-04-14T20:34:58.82131Z",
     "shell.execute_reply": "2024-04-14T20:34:58.819979Z",
     "shell.execute_reply.started": "2024-04-14T20:34:58.639794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Select prediction from model using confidence\n",
    "def classify_rules(models_preds_probs):\n",
    "    # Find model that has highest confidence about prediction\n",
    "    best_model_index = np.argmax([model_preds_probs.max() for model_preds_probs in models_preds_probs])\n",
    "    best_model_preds_probs = models_preds_probs[best_model_index]\n",
    "    \n",
    "    # Find face for which the model has the highest confidence about prediction\n",
    "    face_index = np.argmax([preds_probs.max() for preds_probs in best_model_preds_probs])\n",
    "    best_pred_prob = best_model_preds_probs[face_index]\n",
    "    \n",
    "    # Make prediction by choosing the one with highest confidence from all models\n",
    "    prediction = np.argmax(best_pred_prob)\n",
    "    \n",
    "    # Predict the other class (0) if other models don't agree with model with highest confidence about prediction\n",
    "    min_conf_prediction_face = min([model_preds_probs[face_index][prediction] for model_preds_probs in models_preds_probs])\n",
    "    if min_conf_prediction_face < 0.6:\n",
    "        return 0\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# combine the results from both classifers based on confidence\n",
    "test_y_star = [classify_rules([test_y_prob_hog[test_X_indices == i], test_y_prob_pca[test_X_indices == i]]) for i in range(len(test_X_faces))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During testing, it became evident that Logistic Regression (LR) with Histogram of Oriented Gradients (HOG) outperformed as a standalone model in classifying faces. However, when combining both Support Vector Machine (SVM) with Principal Component Analysis (PCA) and LR with HOG, the combined score surpassed that of LR with HOG alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.103853,
     "end_time": "2021-03-08T07:59:10.903341",
     "exception": false,
     "start_time": "2021-03-08T07:59:10.799488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Publishing best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:35:55.371889Z",
     "iopub.status.busy": "2024-04-14T20:35:55.370778Z",
     "iopub.status.idle": "2024-04-14T20:35:55.412327Z",
     "shell.execute_reply": "2024-04-14T20:35:55.410745Z",
     "shell.execute_reply.started": "2024-04-14T20:35:55.371826Z"
    },
    "papermill": {
     "duration": 0.120392,
     "end_time": "2021-03-08T07:59:11.127762",
     "exception": false,
     "start_time": "2021-03-08T07:59:11.00737",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = test.copy().drop('img', axis = 1)\n",
    "submission['class'] = test_y_star\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:35:55.415458Z",
     "iopub.status.busy": "2024-04-14T20:35:55.414644Z",
     "iopub.status.idle": "2024-04-14T20:35:55.430596Z",
     "shell.execute_reply": "2024-04-14T20:35:55.428443Z",
     "shell.execute_reply.started": "2024-04-14T20:35:55.4154Z"
    },
    "papermill": {
     "duration": 0.122516,
     "end_time": "2021-03-08T07:59:11.356409",
     "exception": false,
     "start_time": "2021-03-08T07:59:11.233893",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.116655,
     "end_time": "2021-03-08T07:59:11.577703",
     "exception": false,
     "start_time": "2021-03-08T07:59:11.461048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Discussion\n",
    "\n",
    "In summary, the following contributions were made:\n",
    "\n",
    "**Preprocessing**\n",
    "\n",
    "The project began with experiments involving various preprocessing techniques. Despite efforts to fine-tune the parameters of the provided HAAR detector to capture more faces, significant limitations were encountered, including an increase in false positives. An alternative approach using a pre-trained DNN was also tested, but it failed to outperform the HAAR detector and resulted in suboptimal cropping, particularly cutting out parts of facial features, such as chins, across multiple images. Ultimately, the HAAR detector was retained due to its comparatively better performance.\n",
    "\n",
    "**Feature Extractors**\n",
    "\n",
    "Three distinct feature extraction methods were explored: Histogram of Oriented Gradients (HOG), Scale-Invariant Feature Transform (SIFT), and Principal Component Analysis (PCA).\n",
    "\n",
    "- HOG counts the occurrences of gradient orientation in localized sections of an image, focusing on the structure or shape of the object.\n",
    "- SIFT, although explored, was not integrated into the classifiers due to challenges with varying feature counts per image, which complicated feature manipulation.\n",
    "- PCA, which used Singular Value Decomposition (SVD) to derive eigenfaces from images, proved to be a promising approach. After fine-tuning the number of components, it was determined that using 50 components produced the best results.\n",
    "\n",
    "**Metrics**\n",
    "\n",
    "The classifiers were evaluated using a variety of metrics. Initially, accuracy was used, but to gain more detailed insights, additional metrics such as `classification_report` and `cross_validation` from sklearn were employed. These more refined metrics, particularly `classification_report`, offered valuable precision and recall information for each individual label.\n",
    "\n",
    "**Classifier**\n",
    "\n",
    "The integration of the previously discussed techniques led to the implementation of the classifiers. Different models were tested alongside various feature extractors to determine the most effective combination. The best-performing approach was identified as a dual-model strategy, combining an SVC classifier for PCA features and a logistic regression classifier for HOG features. Image classification was based on the model with the highest confidence in its assigned label. Additionally, training data augmentation was explored, which proved to be beneficial for improving model generalization and demonstrated effectivenes\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7751321,
     "sourceId": 70926,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
